{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Accessing & Organizing NCEI/NOAA Data\n",
    "------------------------------------------------------------------------------\n",
    "\n",
    "For this tutorial we will be using some U.S. Hourly Precipitation Data, published by NOAA:\n",
    "\n",
    "**Citation:**\n",
    "\n",
    "> National Climatic Data Center, NESDIS, NOAA, U.S. Department of Commerce (2016). _U.S. Hourly Precipitation Data [dataset]_. NCEI DSI 3240_01 \n",
    "\n",
    "> National Climatic Data Center, NESDIS, NOAA, U.S. Department of Commerce (2016). _U.S. Hourly Precipitation Data [dataset]_. NCEI DSI 3240_02\n",
    "\n",
    "From the webpage at <https://data.nodc.noaa.gov/cgi-bin/iso?id=gov.noaa.ncdc:C00313>, we see that data can be downloaded via the FTP server at <ftp://ftp.ncdc.noaa.gov/pub/data/hourly_precip-3240/>.\n",
    "\n",
    "For our purposes, we are only going to download a small subset of the available data.\n",
    "\n",
    "Our objective is to use shell commands to download, organize, and prepare the data for processing.\n",
    "\n",
    "We will use the `wget` command line utility to download the data - if for any reason you are unable to install or get `wget` working, the data are available for download from <https://unmm-my.sharepoint.com/:u:/g/personal/jwheel01_unm_edu/EQ4cpOBAiHVEhSUdkfQFSAcBgEnWUViyqdIXKvwglz6bWQ?e=flQL41>.\n",
    "\n",
    "### Create the Project Directory\n",
    "\n",
    "First we need to create a working directory for the project, using our `home` directory (Mac and Linux) or our user directory (Windows).\n",
    "\n",
    "Within the shell, take a moment to determine which directory you are in, change to your `home` directory, and verify that you have done so.\n",
    "\n",
    "Now use the `mkdir` command to create a directory named *precipitation_data*. Note that, similar to `cd`, the `mkdir` command does not print any output. Once done, change into this directory.\n",
    "\n",
    "```\n",
    "mkdir precipitation_data\n",
    "```\n",
    "\n",
    "### Download Data\n",
    "\n",
    "One way to get the data we need is to use a web browser to download the files from the FTP site linked above. This is straight forward but presents two problems:\n",
    "\n",
    "1. Each directory contains multiple tarfile of data - unless we use a bulk download manager, the more data we need, the longer it will take to download.\n",
    "2. Unless we specify the download directory each time, the files will be saved to some other location on our computer and we will have to move them to our *precipitation_data* directory.\n",
    "\n",
    "This is exactly the type of repetitive and error prone task that benefits from batch processing using shell commands. We're going to use a command line utility called `wget` to download the complete content of each directory. First, we can use the standard `--help` flag to check the usage and parameters.\n",
    "\n",
    "```\n",
    "wget --help\n",
    "```\n",
    "\n",
    "More info on `wget` is available at <https://www.gnu.org/software/wget/>.\n",
    "\n",
    "Looking at the help info, we see there are a couple of ways we can simplify our download process. One option is to use the `-r` flag, which recursively follows the links found within the specified URL. In our case, this will result in downloading all of the files in whichever FTP directory we specify when we run the command:\n",
    "\n",
    "```\n",
    "wget -r ftp://ftp.ncdc.noaa.gov/pub/data/hourly_precip-3240/66/\n",
    "```\n",
    "\n",
    "**Quick check:** What's one way we can re-run the command above for the other two directories without having to paste in or type the other two URLs?\n",
    "\n",
    "This strategy works fine for a small handful of URLs, but itself becomes repetitive (and error prone) if we run the command manually to download the contents of many more directories. Referring back to the help info, another option is to use the `-i` flag to specify an input file that contains a list of the URLs we want to harvest from.\n",
    "\n",
    "There are multiple ways to create the file we need for this, including using a text editor in the shell itself. For today, we will instead create the file in the shell using the `touch` command and then use our operating system's default text editor to add some URLs.\n",
    "\n",
    "```\n",
    "touch --help\n",
    "```\n",
    "\n",
    "After consulting the help info, let's create an empty file called `urls.txt`.\n",
    "\n",
    "```\n",
    "touch urls.txt\n",
    "```\n",
    "\n",
    "`touch` is another command that doesn't print any output. How can we verify our file was created?\n",
    "\n",
    "Open `urls.xt` with a text editor and paste in the following lines:\n",
    "\n",
    "```\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/hourly_precip-3240/51/\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/hourly_precip-3240/50/\n",
    "ftp://ftp.ncdc.noaa.gov/pub/data/hourly_precip-3240/48/\n",
    "```\n",
    "\n",
    "Keep in mind that we can add as many URLs as we like and will still only have to run a single `wget` command. Even better, this file becomes documentation that we can use to double check or replicate/reproduce our work.\n",
    "\n",
    "We can now use `wget` with the `-r` and `-i` flags to download the contents of the FTP URLs listed in `urls.txt`.\n",
    "\n",
    "```\n",
    "wget -r -i urls.txt\n",
    "```\n",
    "\n",
    "The final lines of the output gives us some idea of the effort we saved:\n",
    "\n",
    "```\n",
    "FINISHED --2019-02-05 20:32:07--\n",
    "Total wall clock time: 39s\n",
    "Downloaded: 42 files, 11M in 21s (521 KB/s)\n",
    "```\n",
    "\n",
    "#### Exercise\n",
    "\n",
    "Documentation for the data are available from the FTP site linked above. Using shell commands:\n",
    "\n",
    "1. Create a *documentation* directory in the *precipitation_data* directory. Change into this directory.\n",
    "2. Use one of the above methods to download the following two files into the *documentation* directory:\n",
    "    * dsi3240.pdf\n",
    "    * readme.txt\n",
    "    \n",
    "### Access the Data: Unzip and Move Files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
